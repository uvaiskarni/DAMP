{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 450646 entries, 0 to 450645\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   Timestamp     450646 non-null  datetime64[ns]\n",
      " 1   Station Name  450646 non-null  object        \n",
      " 2   PM10          267321 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 10.3+ MB\n",
      "None\n",
      "                PM10\n",
      "count  267321.000000\n",
      "mean       18.960425\n",
      "std        19.918945\n",
      "min        -3.040000\n",
      "25%         8.000000\n",
      "50%        13.400000\n",
      "75%        22.400000\n",
      "max       447.600000\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"G:\\Uppsala Docs\\period5&6\\ProcessedData\\2015-2019_sensorData.csv\",\n",
    "                 usecols=['Stop','Station Name','PM10'])\n",
    "\n",
    "# selecting station #Stockholm E4/E20 Lilla Essingen\n",
    "#df = df[df['Station Name']=='#Stockholm Torkel Knutssongatan']\n",
    "\n",
    "# Rename Stop to Time\n",
    "df = df.rename(columns={\"Stop\": \"Timestamp\"})\n",
    "\n",
    "# convert columns to date\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.  13.  12.8 ...  3.   2.8  4.6]\n",
      "Shape:\n",
      " (450646, 1)\n",
      "Data Set:\n",
      " [[57. ]\n",
      " [13. ]\n",
      " [12.8]\n",
      " [13.9]]\n",
      "Normalised Data Set:\n",
      " [[0.13323274]\n",
      " [0.03559382]\n",
      " [0.03515001]\n",
      " [0.03759098]]\n",
      "X:\n",
      " [[0.13323274]\n",
      " [0.03559382]\n",
      " [0.03515001]\n",
      " [0.03759098]\n",
      " [0.03803479]]\n",
      "X shape:\n",
      " (450641, 5, 1)\n",
      "y:\n",
      " 0.03870051482336233\n",
      "y shape:\n",
      " (450641,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Modyfying data for traning LSTM \n",
    "\n",
    "# selecting PM10 column\n",
    "data_set  = df.iloc[:,2].values\n",
    "\n",
    "# replace missing values with -1 (later used to mask nan)\n",
    "nan_index  = np.isnan(data_set)\n",
    "data_set[np.isnan(data_set)] = -1\n",
    "print(data_set)\n",
    "data_set  = data_set.reshape(-1,1)\n",
    "print(\"Shape:\\n\",data_set.shape)\n",
    "print(\"Data Set:\\n\",data_set[0:4])\n",
    "\n",
    "# Normalisation of Data\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "data_set_scaled = sc.fit_transform(data_set)\n",
    "print(\"Normalised Data Set:\\n\",data_set_scaled[0:4])\n",
    "\n",
    "# Generating LSTM featurse with Lag and Y\n",
    "X = []\n",
    "y = []\n",
    "for i in range(5, len(data_set)):\n",
    "    X.append(data_set_scaled[i-5:i, 0])\n",
    "    y.append(data_set_scaled[i, 0])\n",
    "X, y = np.array(X), np.array(y)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "print(\"X:\\n\",X[0])\n",
    "print(\"X shape:\\n\",X.shape)\n",
    "print(\"y:\\n\",y[0])\n",
    "print(\"y shape:\\n\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data distribution Across Stations:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Classification'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bca84062fd67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data distribution Across Stations:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m print(df_2.groupby(['Station Name']).aggregate(\n\u001b[1;32m---> 13\u001b[1;33m     'count').drop(['Timestamp','Classification'],1))\n\u001b[0m\u001b[0;32m     14\u001b[0m df_2.groupby(['Station Name']).aggregate(\n\u001b[0;32m     15\u001b[0m     'count').drop(['Timestamp','Classification'],1).plot(figsize = (15,10),grid=True,subplots=True)\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\damp\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4165\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4166\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4167\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4168\u001b[0m         )\n\u001b[0;32m   4169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\damp\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3876\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3877\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3878\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3880\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\damp\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3910\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3911\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3912\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3913\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Programs\\Anaconda\\envs\\damp\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5275\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5276\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5277\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Classification'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## splitting data into test and train\n",
    "#len of the \n",
    "td_percentage = 0.20\n",
    "test_size = int(len(X)*td_percentage)\n",
    "\n",
    "# segmenting 2018 may data\n",
    "start_date = '2018-01-01 00:00:00'\n",
    "end_date  = '2018-10-31 23:59:59'\n",
    "df_2 = df[(df['Timestamp'] >= start_date) & (df['Timestamp'] <= end_date)]\n",
    "# Data distribution Across Stations in 2015 month\n",
    "print('Data distribution Across Stations:')\n",
    "print(df_2.groupby(['Station Name']).aggregate(\n",
    "    'count').drop(['Timestamp','Classification'],1))\n",
    "df_2.groupby(['Station Name']).aggregate(\n",
    "    'count').drop(['Timestamp','Classification'],1).plot(figsize = (15,10),grid=True,subplots=True)\n",
    "\n",
    "X_train = X[0:X.shape[0]-test_size]\n",
    "y_train = y[0:X.shape[0]-test_size]\n",
    "X_test = X[0:test_size]\n",
    "y_test = y[0:test_size]\n",
    "\n",
    "print(\"X_train_shape:\\n\",X_train.shape)\n",
    "print(\"y_train_shape:\\n\",y_train.shape)\n",
    "print(\"X_test_shape:\\n\",X_test.shape)\n",
    "print(\"y_test_shape:\\n\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
